table(mastercopy2[,c("Gender","Q9K")])[1,]/sum(table(mastercopy2[,c("Gender","Q9K")])[1,])*100
table(mastercopy2[,c("Gender","Q9K")])[2,]/sum(table(mastercopy2[,c("Gender","Q9K")])[2,])*100
table(mastercopy2[,c("Gender","Q10C1")])[1,]/sum(table(mastercopy2[,c("Gender","Q7K")])[1,])*100
table(mastercopy2[,c("Gender","Q10C1")])[2,]/sum(table(mastercopy2[,c("Gender","Q7K")])[2,])*100
#Running DA
Gender_Knowledge_DA <- lda(Gender~q2k+q3k+Q6K,data=mastercopy2)
Gender_Knowledge_DA
#LDA prediction
lda.testing <- predict(Gender_Knowledge_DA)
#confusion matrix
accuracy <- table(lda.testing$class,mastercopy2$Gender)
accuracy
sum(accuracy[row(accuracy) == col(accuracy)]) / sum(accuracy)
#Percentage for gender vs q1k
table(mastercopy2[,c("Gender","q1k")])[1,]/sum(table(mastercopy2[,c("Gender","q1k")])[1,])*100
table(mastercopy2[,c("Gender","q1k")])[2,]/sum(table(mastercopy2[,c("Gender","q1k")])[2,])*100
#Percentage for Education vs q1k
table(mastercopy2[,c("Education","q1k")])[1,]/sum(table(mastercopy2[,c("Education","q1k")])[1,])*100
table(mastercopy2[,c("Education","q1k")])[2,]/sum(table(mastercopy2[,c("Education","q1k")])[2,])*100
table(mastercopy2[,c("Education","q1k")])[3,]/sum(table(mastercopy2[,c("Education","q1k")])[3,])*100
table(mastercopy2[,c("Income","q1k")])
#Percentage for income vs q1k
table(mastercopy2[,c("Income","q1k")])[1,]/sum(table(mastercopy2[,c("Income","q1k")])[1,])*100
table(mastercopy2[,c("Income","q1k")])[2,]/sum(table(mastercopy2[,c("Income","q1k")])[2,])*100
table(mastercopy2[,c("Income","q1k")])[3,]/sum(table(mastercopy2[,c("Income","q1k")])[3,])*100
#Running PCA on Attitude and preceptions
names(mastercopy2[,c("Q10C1","Q10C2","Q10C3","Q10C4","Q10C5","Q10C6","Q10C7")])
res.pca2 <- prcomp(mastercopy2[,c("Q10C1","Q10C2","Q10C3","Q10C4","Q10C5","Q10C6","Q10C7")])
res.pca2
summary(res.pca2)
library("factoextra")
eig.val2 <- get_eigenvalue(res.pca2)
eig.val2
dimT2 <- c(1:8)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT2, eig.val2$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca2)
#Loading score
fviz_pca_var(res.pca2,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#there is strong corelation between C1 and C2
#there is strong corelation between C3 and C4
#there is strong corelation between C5 and C6 and C7
#Percentage for gender vs Q10C4
table(mastercopy2[,c("Gender","Q10C4")])[1,]/sum(table(mastercopy2[,c("Gender","Q10C4")])[1,])*100
table(mastercopy2[,c("Gender","Q10C4")])[2,]/sum(table(mastercopy2[,c("Gender","Q10C4")])[2,])*100
#Percentage for Education vs Q10C4
table(mastercopy2[,c("Education","Q10C4")])[1,]/sum(table(mastercopy2[,c("Education","Q10C4")])[1,])*100
table(mastercopy2[,c("Education","Q10C4")])[2,]/sum(table(mastercopy2[,c("Education","Q10C4")])[2,])*100
table(mastercopy2[,c("Education","Q10C4")])[3,]/sum(table(mastercopy2[,c("Education","Q10C4")])[3,])*100
table(mastercopy2[,c("Income","q1k")])
#Percentage for income vs q1k
table(mastercopy2[,c("Income","Q10C4")])[1,]/sum(table(mastercopy2[,c("Income","Q10C4")])[1,])*100
table(mastercopy2[,c("Income","Q10C4")])[2,]/sum(table(mastercopy2[,c("Income","Q10C4")])[2,])*100
table(mastercopy2[,c("Income","Q10C4")])[3,]/sum(table(mastercopy2[,c("Income","Q10C4")])[3,])*100
table(mastercopy2$Q10C1)
table(mastercopy2$Q10C2)
table(mastercopy2$Q10C3)
table(mastercopy2$Q10C4)
table(mastercopy2$Q10C5)
table(mastercopy2$Q10C6)
table(mastercopy2$Q10C7)
table(mastercopy2$Q10C7)
# Fit the full model
full.model <- lm(Gender ~., data = mastercopy2[,c("Gender","Q10C5","Q10C6","Q10C7")])
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
summary(step.model)
#As per knowledge and reserach Q19 and demographic donot contribute much so we remove those from columns
#Try Factor Analysis
##Factor Analysis
#Data without question 19
data_without19 <- mastercopy2[,-(61:66)]
#we delete col 19 as it is not that much important
#Now we also dont need demographic as per requirement of project
data<-data_without19[,-(1:5)]
#DEcide number of initial factors
library(psych)
decidefactor <- fa.parallel(data,fm ='ml', fa = 'fa')
#According to parallel analysis we have 11 factors
#As we see by the parallel analysis number of factor should be 11.
#Try 1
factana1 <- fa(data,nfactors =11)
fa.diagram(factana1)
<<<<<<< HEAD
NewDATA<- mastercopy2[,-(1:5)]
Data_only_Q <- NewDATA[,-(56:61)]
fact_An <- factanal(Data_only_Q, factors = 20)
fact_An
library(psych)
fa.diagram(fact_An$loadings)
=======
library(psych)
fa.diagram(factana1$loadings)
>>>>>>> 2dac7486110de8cac707b95eb128888a3a536102
install.packages("GPArotation")
library(GPArotation)
factanatry1 <- fa(data,nfactors = 11)
library(psych)
fa.diagram(factanatry1)
colnames(factanatry1$loadings)
colnames(factanatry1$loadings)=c("PlasBeh",
"ReduInt",
"SysResp",
"SocAffect"
,"NatrConc",
"HealConc"
,"CondBeh"
,"IngEff"
,"BehChan"
,"ConEfft",
"Diff")
#As the p value is very low so model is not good.
#keeping only correlated variables keeping cutoff 0.1
install.packages("caret")
library('caret')
<<<<<<< HEAD
df_cor = findCorrelation(cor(Data_only_Q), cutoff=0.30)
df_cor
hc= sort(df_cor)
data = Data_only_Q[, c(hc)]
factana <- fa(data,nfactors = 8)
=======
data_corelated_try1 = findCorrelation(cor(data), cutoff=0.1)
data_corelated_try1
hc= sort(data_corelated_try1)
data_only_corelated_try1 = data[, c(hc)]
dim(data_only_corelated_try1)
#We are left with only 42 variables.
factana <- fa(data_only_corelated_try1,nfactors = 11)
>>>>>>> 2dac7486110de8cac707b95eb128888a3a536102
fa.diagram(factana)
#Model Donot improve much So we need to increase the cutoff
#keeping only correlated variables keeping cutoff 0.2
data_corelated_try2 = findCorrelation(cor(data), cutoff=0.2)
data_corelated_try2
hc= sort(data_corelated_try2)
data_only_corelated_try2 = data[, c(hc)]
dim(data_only_corelated_try2)
#We are left with only 31 variables.
<<<<<<< HEAD
table(mastercopy2$Gender,mastercopy2$q1k)
mastercopy2$Age
chisq.test(table(mastercopy2$Gender,mastercopy2$q1k),correct = FALSE)  #p-value = 0.0006377 , Reject NUll it means gender and quetion 1 is dependent on each other.
colnames(fa_psych$loadings) <- c("Behaviour[Reduce]", "Intention[Reduce]","Personal Accountability[Reduce]",
"Health Concern [Att.]", "Social Conditional Intention",
"Impediments","Environemental Concern [Att.]")
=======
factana <- fa(data_only_corelated_try2,nfactors = 11)
fa.diagram(factana)
#Model Improves but we will try with cut off 0.3
#keeping only correlated variables keeping cutoff 0.3
data_corelated_try3 = findCorrelation(cor(data), cutoff=0.3)
data_corelated_try3
hc= sort(data_corelated_try3)
data_only_corelated_try3 = data[, c(hc)]
dim(data_only_corelated_try3)
#We are left with only 16 variables.
#First model with 11 factors
fact_ana2 <- factanal(data_only_corelated_try3, factors = 11)
fact_ana2
factana2 <- fa(data_only_corelated_try3,nfactors =11)
fa.diagram(factana2)
#Second model with 10 factors
fact_ana3 <- factanal(data_only_corelated_try3, factors = 10)
fact_ana3
factana3 <- fa(data_only_corelated_try3,nfactors =10)
fa.diagram(factana3)
#Third model with 9 factors
fact_ana4 <- factanal(data_only_corelated_try3, factors = 9)
fact_ana4
factana4 <- fa(data_only_corelated_try3,nfactors =9)
fa.diagram(factana4)
colnames(fact_ana4$loadings) =c()
#Fourth model with 8 factors
fact_ana5 <- factanal(data_only_corelated_try3, factors = 8)
fact_ana5
factana5 <- fa(data_only_corelated_try3,nfactors =8)
fa.diagram(factana5)
colnames(factana4$loadings) <- c("RecBeh",
"ManRes",
"behKnow",
"SocAff",
"DiscNylon",
"Conhea",
"Conenv",
"PerBeh",
"KnowSou")
# Chi Square Analysis
#CHiOne fo  gender
chisq.test(table(mastercopy2$Gender,mastercopy2$Q18I1),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q18I2),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q18I3),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q15C4),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q15C3),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q15C2),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q17P4),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q17P3),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q17P5),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q11C2),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q11C4),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q11C5),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q11C1),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q17P1),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q17P2),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q10C1),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q10C2),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q10C3),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q10C5),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q10C6),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q12C1),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q12C2),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q5K4),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q5K5),correct = FALSE)
chisq.test(table(mastercopy2$Gender,mastercopy2$Q5K1),correct = FALSE)
#Chi Square with Education
chisq.test(table(mastercopy2$Education,mastercopy2$Q18I1),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q18I2),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q18I3),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q15C4),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q15C3),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q15C2),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q17P4),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q17P3),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q17P5),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q11C2),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q11C4),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q11C5),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q11C1),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q17P1),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q17P2),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q10C1),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q10C2),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q10C3),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q10C5),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q10C6),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q12C1),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q12C2),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q5K4),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q5K5),correct = FALSE)
chisq.test(table(mastercopy2$Education,mastercopy2$Q5K1),correct = FALSE)
#Chi Square with occupation
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q18I1),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q18I2),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q18I3),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q15C4),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q15C3),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q15C2),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q17P4),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q17P3),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q17P5),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q11C2),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q11C4),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q11C5),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q11C1),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q17P1),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q17P2),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q10C1),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q10C2),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q10C3),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q10C5),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q10C6),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q12C1),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q12C2),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q5K4),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q5K5),correct = FALSE)
chisq.test(table(mastercopy2$Occupation,mastercopy2$Q5K1),correct = FALSE)
#Chi Square with Income
chisq.test(table(mastercopy2$Income,mastercopy2$Q18I1),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q18I2),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q18I3),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q15C4),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q15C3),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q15C2),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q17P4),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q17P3),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q17P5),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q11C2),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q11C4),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q11C5),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q11C1),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q17P1),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q17P2),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q10C1),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q10C2),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q10C3),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q10C5),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q10C6),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q12C1),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q12C2),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q5K4),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q5K5),correct = FALSE)
chisq.test(table(mastercopy2$Income,mastercopy2$Q5K1),correct = FALSE)
#####################################################################################################################
# without mice FA
No_miceData <- read.csv("final_No_mice.csv")
##Factor Analysis
#Data without question 19
data_without19 <- No_miceData[,-(61:66)]
#we delete col 19 as it is not that much important
#Now we also dont need demographic as per requirement of project
data<-data_without19[,-(1:5)]
# PCA
# A Demographic and Knowledge
View(No_miceData)
No_miceData[1:19]
noMicePca <- prcomp(No_miceData[1:19],scale= TRUE)
summary(noMicePca)
library("factoextra")
noMiceEig <- get_eigenvalue(noMicePca)
noMiceEig
dimNomice <- c(1:19)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimNomice, noMiceEig$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(noMicePca)
#Loading score
fviz_pca_var(noMicePca,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#
factana12 <- fa(No_miceData[6:19],nfactors =8)
fa.diagram(factana12)
summary(factana12)
factanal12 <- factanal(No_miceData[1:19], factors = 8)
factanal12
####
decidefactor <- fa.parallel(No_miceData[6:19],fm ='ml', fa = 'fa')
#According to parallel analysis we have 11 factors
#As we see by the parallel analysis number of factor should be 11.
#Try 1
#Third model with 12 factors
factana7 <- fa(data,nfactors =12)
fa.diagram(factana7)
summary(factana7)
library(psych)
fa.diagram(factana7$loadings)
factanal7 <- factanal(data, factors = 12)
factanal7
install.packages("GPArotation")
library(GPArotation)
factana8 <- fa(data,nfactors = 11)
fa.diagram(factana8)
summary(factana8)
factanal8 <- factanal(data, factors = 11)
factanal8
#keeping only correlated variables keeping cutoff 0.1
install.packages("caret")
library('caret')
data_corelatedNoMice = findCorrelation(cor(data), cutoff=0.3)
data_corelatedNoMice
hc1= sort(data_corelatedNoMice)
data_corelatedNoMice = data[, c(hc1)]
dim(data_corelatedNoMice)
#We are left with only 29 variables.
# trying with 11 Factors
factana9 <- fa(data_corelatedNoMice,nfactors = 11)
fa.diagram(factana9)
summary(factana9)
factanal9 <- factanal(data_corelatedNoMice, factors = 11)
factanal9
colnames(factana9$loadings) <- c("reduInt",
"MngRspb",
"RefNyln",
"SocAfct",
"Atitud",
"natConc",
"ruleAbid",
"PercBeh",
"AvoidInt",
"source",
"Environmentlist")
# Trying with 10 factors
factanal10 <- factanal(data, factors = 10)
factanal10
factana10 <- fa(data,nfactors =10)
summary(factana10)
fa.diagram(factana10)
#trying with 9 factors
factana11 <- fa(data,nfactors =9)
fa.diagram(factana11)
summary(factana11)
factanal11 <- factanal(data, factors = 9)
factanal11
#trying with 8 factors
factana11 <- fa(data,nfactors =8)
fa.diagram(factana11)
summary(factana11)
factanal11 <- factanal(data, factors = 8)
factanal11
colnames(factana11$loadings)
colnames(factana11$loadings) <- c("RecBeh",
"MngRspb",
"Rspb",
"SocAfct",
"HltPrcp",
"EnvCons",
"EnvMntlst",
"PercBeh",
"Knldge")
fa.diagram(factana11)
############
# try with corelated
factana12 <- fa(data_corelatedNoMice,nfactors = 12)
fa.diagram(factana12)
summary(factana12)
factana12 <- factanal(data_corelatedNoMice, factors = 12)
factana12
# try with corelated
factana13 <- fa(data_corelatedNoMice,nfactors = 11)
fa.diagram(factana13)
summary(factana13)
factanal13 <- factanal(data_corelatedNoMice, factors = 11)
factanal13
# try with corelated
factana14 <- fa(data_corelatedNoMice,nfactors = 10)
fa.diagram(factana14)
summary(factana14)
factanal14 <- factanal(data_corelatedNoMice, factors = 10)
factanal14
# try with corelated
factana15 <- fa(data_corelatedNoMice,nfactors = 9)
fa.diagram(factana15)
summary(factana15)
factanal15 <- factanal(data_corelatedNoMice, factors = 9)
factanal15
# try with corelated
factana16 <- fa(data_corelatedNoMice,nfactors = 8)
fa.diagram(factana16)
summary(factana16)
factanal16 <- factanal(data_corelatedNoMice, factors = 8)
factanal16
#############################################################################################################################
View(data_only_corelated_try3)
data_only_corelated_try3
#Corelation Short method
cordata <-cor(data_only_corelated_try3)
library(corrplot)
corrplot(cordata, method="number")
#Corelation
cormat <- round(cor(data_only_corelated_try3),2)
head(cormat)
install.packages("reshape2")
library(reshape2)
melted_cormat <- melt(cormat)
head(melted_cormat)
library(ggplot2)
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
geom_tile()
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
# Melt the correlation matrix
library(reshape2)
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Heatmap
library(ggplot2)
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}
# Reorder the correlation matrix
cormat <- reorder_cormat(cormat)
upper_tri <- get_upper_tri(cormat)
# Melt the correlation matrix
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
# Print the heatmap
print(ggheatmap)
ggheatmap +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
>>>>>>> 2dac7486110de8cac707b95eb128888a3a536102
install.packages("GPArotation")
install.packages("GPArotation")
install.packages("caret")
