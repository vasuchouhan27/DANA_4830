Nomice1$Q6K[!Nomice1$Q6K == 1] = 0
#For Q7
Nomice1$Q7K[!Nomice1$Q7K == c(2,3)] = 0
Nomice1$Q7K[Nomice1$Q7K == c(2,3)] = 1
#For Q8
Nomice1$Q8K[!Nomice1$Q8K == 1] = 0
#For Q9
Nomice1$Q9K[!Nomice1$Q9K == 1] = 0
Nomice1$knwSum <- (Nomice1$q1k+Nomice1$q2k+Nomice1$q3k+Nomice1$q4+Nomice1$Q6K+Nomice1$Q7K+Nomice1$Q8K+Nomice1$Q9K)
Nomice1$sum5 <- (Nomice1$Q5K1+Nomice1$Q5K2+Nomice1$Q5K3+Nomice1$Q5K4+Nomice1$Q5K5+Nomice1$Q5K6)/6
Nomice1$knwSum <- Nomice1$knwSum + Nomice1$sum5
write.csv(Nomice1,"Nomice1.csv")
# Copy
Nomice2 <- Nomice1
View(Nomice2)
#Import the data and make copy of data
master <- read.csv("Data-screening-1 (1).csv")
mastercopy <- master
#Checking names of columns and remove all those column which are not in appendix or not relative to study.
names(mastercopy)
dim(mastercopy)
#dropping unnecessory rows
mastercopy <- mastercopy[,-c(1:16)]
names(mastercopy)
#dimension of the data set
dim(mastercopy)
#Now removing all the duplicate values if it has. By using package "dplyr".
library("dplyr")
mastercopy<- distinct(mastercopy)
dim(mastercopy)
### Start checking accuarcy for the columns containing DEMOGRAPHIC INFORMATION
#To see unique values
lapply(mastercopy, unique)[1:5]
#Except Education and Occupation, all other columns have wrong data entry. We will correct it acoording to the appendix and remove all the values which are out of range of appendix. Also the children below 5 or above 100 is for sure is wrong we need to remove that one.
#Gender
mastercopy$Gender <- factor(mastercopy$Gender, levels = c(1,2))
#Age
mastercopy$Age[mastercopy$Age=="16 years-old"] <- "16"
library("stringr")
mastercopy$Age <-str_replace_all(mastercopy$Age, "[abcdefgfhijklmanopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ]", NA_character_)
mastercopy$Age <-strtoi(mastercopy$Age)
#It makes no sense if the person age more than 100 or less tha 5 contribute in survey.
mastercopy$Age[(mastercopy["Age"] < 12)] = NA
mastercopy$Age[(mastercopy["Age"] >100)] =NA
#Income
#as one enntry is "30000" it falls under the category of 3 so to change it.
mastercopy$Income[mastercopy$Income=="30000"] <- "3"
str(mastercopy)
mastercopy$Income <-strtoi(mastercopy$Income)
dim(mastercopy)
### Start checking accuarcy for the columns containing KNOWLEDGE.
lapply(mastercopy, unique)[6:20]
#We need to remove all the values which are out of range. But as only Q6 has some values out of range. So we will replace those values with Null values.
mastercopy$Q6K <- factor(mastercopy$Q6K, levels = c(1,2))
### Start checking accuarcy for the columns containing ATTITUDE AND PERCEPTION.
lapply(mastercopy,unique)[21:27]
### Start checking accuarcy for the columns containing SOCIAL NORMS AFFECTING PLASTIC CHANGING INTENTION AND BEHAVIORS.
lapply(mastercopy, unique)[28:32]
#As the question 11 has only three option to select, so we will remove other values,
mastercopy$Q11C1 <- factor(mastercopy$Q11C1, levels = c(1,2,3))
mastercopy$Q11C2 <- factor(mastercopy$Q11C2, levels = c(1,2,3))
mastercopy$Q11C3 <- factor(mastercopy$Q11C3, levels = c(1,2,3))
mastercopy$Q11C4 <- factor(mastercopy$Q11C4, levels = c(1,2,3))
mastercopy$Q11C5 <- factor(mastercopy$Q11C5, levels = c(1,2,3))
### Start checking accuarcy for the columns containing PERCEIVED BEHAVIOR CONTROL OVER PLASTIC BEHAVIOR INTENTION AND BEHAVIORAL CHANGE
lapply(mastercopy, unique)[33:52]
#As in Q12, option 8 is not there. Now, we will remove that column.
library("dplyr")
mastercopy <- mastercopy[ -c(39) ]
mastercopy$Q12C1 <- factor(mastercopy$Q12C1, levels = c(1,2,3,4,5,6))
mastercopy$Q12C2 <- factor(mastercopy$Q12C2, levels = c(1,2,3,4,5,6))
mastercopy$Q12C3 <- factor(mastercopy$Q12C3, levels = c(1,2,3,4,5,6))
mastercopy$Q12C4 <- factor(mastercopy$Q12C4, levels = c(1,2,3,4,5,6))
mastercopy$Q12C5 <- factor(mastercopy$Q12C5, levels = c(1,2,3,4,5,6))
mastercopy$Q12C6 <- factor(mastercopy$Q12C6, levels = c(1,2,3,4,5,6))
mastercopy$Q13C1 <- factor(mastercopy$Q13C1, levels = c(1,2,3))
mastercopy$Q13C2 <- factor(mastercopy$Q13C2, levels = c(1,2,3))
mastercopy$Q13C3 <- factor(mastercopy$Q13C3, levels = c(1,2,3))
mastercopy$Q13C4 <- factor(mastercopy$Q13C4, levels = c(1,2,3))
mastercopy$Q13C5 <- factor(mastercopy$Q13C5, levels = c(1,2,3))
mastercopy$Q13C6 <- factor(mastercopy$Q13C6, levels = c(1,2,3))
lapply(mastercopy, unique)[52:61]
lapply(mastercopy, unique)[62:65]
#So, We can see that 5th sub question in Q18 is not recorded. And all other data entries are have range from 1 to 5 so we need to remove the 6 level.
mastercopy$Q18I1 <- factor(mastercopy$Q18I1, levels = c(1,2,3,4,5))
mastercopy$Q18I2 <- factor(mastercopy$Q18I2, levels = c(1,2,3,4,5))
mastercopy$Q18I3 <- factor(mastercopy$Q18I3, levels = c(1,2,3,4,5))
mastercopy$Q18I4 <- factor(mastercopy$Q18I4, levels = c(1,2,3,4,5))
lapply(mastercopy,unique)[66:71]
names(mastercopy)[66:71] <- c("Q19C1","Q19C2","Q19C3","Q19C4","Q19c5","Q19c6")
dim((mastercopy))
# Missing Values
#Lets have a look on the missing values in our data.
mastercopy1<-mastercopy
write.csv(mastercopy1, file = "mastercopy1.csv")
mastercopy1<-read.csv("mastercopy1.csv",stringsAsFactors = FALSE)
library("naniar")
vis_miss(mastercopy1)
dim(mastercopy1)
# To delete the columns which are having more than 90% DAta
# To delete the rows which are having more than 50% data
mastercopy1<-mastercopy1[which(rowMeans(!is.na(mastercopy1)) > 0.5), ]
mastercopy1<-mastercopy1[,which(colMeans(!is.na(mastercopy1)) > 0.1)]
vis_miss(mastercopy1)
dim(mastercopy1)
#to fill zero in multiple choice questions
#We Start with Q5
names(mastercopy1[11:16])
mastercopy1[11:16][is.na(mastercopy1[11:16])] <- 0
#with Q12
lapply(mastercopy1,names)[33:38]
mastercopy1[33:38][is.na(mastercopy1[33:38])] <- 0
#with Q13
names(mastercopy1[39:43])
mastercopy1[39:43][is.na(mastercopy1[39:43])] <- 0
mastercopy1[39:43][mastercopy1[39:43] > 1] <- 1
#with Q15
names(mastercopy1)[45:49]
mastercopy1[45:49][is.na(mastercopy1[45:49])] <- 0
#with Q16
names(mastercopy1)[50:52]
mastercopy1[50:52][is.na(mastercopy1[50:52])] <- 0
#with Q19
names(mastercopy1)[62:67]
mastercopy1[62:67][is.na(mastercopy1[62:67])] <- 0
dim(mastercopy1)
vis_miss(mastercopy1)
# Creating a data set by just removing null values.
noMiceDataset <- na.omit(mastercopy1)
dim(noMiceDataset)
vis_miss(noMiceDataset)
#Finally import the noMiceData  set
write.csv(noMiceDataset,"final_No_mice.csv", row.names = FALSE)
#Summary of the data
summary(mastercopy1)
#Q19 descriptive analysis
table(mastercopy1$Q19C1)
table(mastercopy1$Q19C2)
table(mastercopy1$Q19C3)
table(mastercopy1$Q19C4)
table(mastercopy1$Q19c5)
table(mastercopy1$Q19c6)
#Applying Mice to fill null values
library(mice)
nomissdf= mice(mastercopy1)
df1=complete(nomissdf,2)
summary(df1)
library(naniar)
vis_miss(df1)
mastercopy2 <- df1
#Finally import the Final data set
write.csv(mastercopy2,"final.csv", row.names = FALSE)
##Make Sure Q12,Q13 and Q19 are of making orders
#it is priority based. For Q19 we have 6 options
#19c1 to 19c6 and first row has values 2,3,4,5,1,6 in order
#or priorities for the first person.
names(mastercopy2[1:5])
#PCA
res.pca0 <- prcomp(mastercopy2[1:5],scale= TRUE)
summary(res.pca0)
plot(res.pca0)
screeplot(res.pca0,type="line",main="Scree Plot")
library("factoextra")
eig.val0 <- get_eigenvalue(res.pca0)
eig.val0
dimT0 <- c(1:5)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT0, eig.val0$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca0)
#Loading score
fviz_pca_var(res.pca0,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# A. KNOWLEGDE
res.pca1 <- prcomp(mastercopy2[6:19],scale= TRUE)
summary(res.pca1)
library("factoextra")
eig.val1 <- get_eigenvalue(res.pca1)
eig.val1
dimT1 <- c(1:14)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT1, eig.val1$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca1)
#Loading score
fviz_pca_var(res.pca1,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# B. ATTITUDE AND PERCEPTION
names(mastercopy2[20:26])
res.pca2 <- prcomp(mastercopy2[20:26],scale= TRUE)
summary(res.pca2)
library("factoextra")
eig.val2 <- get_eigenvalue(res.pca2)
eig.val2
dimT2 <- c(1:7)
dimT2
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT2, eig.val2$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca2)
#PCA
res.pca0 <- prcomp(mastercopy2[1:5],scale= TRUE)
summary(res.pca0)
plot(res.pca0)
screeplot(res.pca0,type="line",main="Scree Plot")
library("factoextra")
eig.val0 <- get_eigenvalue(res.pca0)
eig.val0
dimT0 <- c(1:5)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT0, eig.val0$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca0)
#Loading score
fviz_pca_var(res.pca0,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# A. KNOWLEGDE
res.pca1 <- prcomp(mastercopy2[6:19],scale= TRUE)
summary(res.pca1)
library("factoextra")
eig.val1 <- get_eigenvalue(res.pca1)
eig.val1
dimT1 <- c(1:14)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT1, eig.val1$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca1)
#Loading score
fviz_pca_var(res.pca1,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# B. ATTITUDE AND PERCEPTION
names(mastercopy2[20:26])
res.pca2 <- prcomp(mastercopy2[20:26],scale= TRUE)
summary(res.pca2)
library("factoextra")
eig.val2 <- get_eigenvalue(res.pca2)
eig.val2
dimT2 <- c(1:7)
dimT2
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT2, eig.val2$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca2)
#Loading Score
fviz_pca_var(res.pca2,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#Loading score
fviz_pca_var(res.pca1,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# B. ATTITUDE AND PERCEPTION
names(mastercopy2[20:26])
res.pca2 <- prcomp(mastercopy2[20:26],scale= TRUE)
summary(res.pca2)
library("factoextra")
eig.val2 <- get_eigenvalue(res.pca2)
eig.val2
dimT2 <- c(1:7)
dimT2
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT2, eig.val2$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca2)
#Loading Score
fviz_pca_var(res.pca2,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#StreePlot
fviz_eig(res.pca2)
#Loading Score
fviz_pca_var(res.pca2,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# c. SOCIAL NORMS AFFECTING PLASTIC CHANGING INTENTION AND BEHAVIORS
names(mastercopy2[27:31])
res.pca3 <- prcomp(mastercopy2[27:31],scale= TRUE)
summary(res.pca3)
library("factoextra")
eig.val3 <- get_eigenvalue(res.pca3)
eig.val3
dimT3 <- c(1:5)
dimT3
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT3, eig.val3$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca3)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT3, eig.val3$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca3)
#Loading Score
fviz_pca_var(res.pca3,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# c. SOCIAL NORMS AFFECTING PLASTIC CHANGING INTENTION AND BEHAVIORS
names(mastercopy2[27:31])
res.pca3 <- prcomp(mastercopy2[27:31],scale= TRUE)
summary(res.pca3)
library("factoextra")
eig.val3 <- get_eigenvalue(res.pca3)
eig.val3
dimT3 <- c(1:5)
dimT3
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT3, eig.val3$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca3)
#Loading Score
fviz_pca_var(res.pca3,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# D. PERCEIVED BEHAVIOR CONTROL OVER PLASTIC BEHAVIOR INTENTION AND BEHAVIORAL CHANGE
names(mastercopy2[32:48])
res.pca4 <- prcomp(mastercopy2[32:48],scale= TRUE)
summary(res.pca4)
library("factoextra")
eig.val4 <- get_eigenvalue(res.pca4)
eig.val4
dimT4 <- c(1:17)
dimT4
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT4, eig.val4$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca4)
#Loading Score
fviz_pca_var(res.pca4,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#Loading Score
fviz_pca_var(res.pca4,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# E. Plastic Related Behaviour
names(mastercopy2[49:56])
res.pca5 <- prcomp(mastercopy2[49:56],scale= TRUE)
summary(res.pca5)
library("factoextra")
eig.val5 <- get_eigenvalue(res.pca5)
eig.val5
dimT5 <- c(1:8)
dimT5
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT5, eig.val5$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca5)
#Loading Score
fviz_pca_var(res.pca5,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# F Intention to change Behaviour
names(mastercopy2[57:60])
res.pca6 <- prcomp(mastercopy2[57:60],scale= TRUE)
summary(res.pca6)
library("factoextra")
eig.val6 <- get_eigenvalue(res.pca6)
eig.val6
dimT6 <- c(1:4)
dimT6
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT6, eig.val6$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca6)
#Loading Score
fviz_pca_var(res.pca6,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#StreePlot
fviz_eig(res.pca6)
#Loading Score
fviz_pca_var(res.pca6,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#Checking answer of gender vs Knowledge
table(mastercopy2[,c("Gender","q1k")])
#Percentage for gender vs q1k
table(mastercopy2[,c("Gender","q1k")])[1,]/sum(table(mastercopy2[,c("Gender","q1k")])[1,])*100
table(mastercopy2[,c("Gender","q1k")])[2,]/sum(table(mastercopy2[,c("Gender","q1k")])[2,])*100
#Percentage for gender vs q2k
table(mastercopy2[,c("Gender","q2k")])[1,]/sum(table(mastercopy2[,c("Gender","q2k")])[1,])*100
table(mastercopy2[,c("Gender","q2k")])[2,]/sum(table(mastercopy2[,c("Gender","q2k")])[2,])*100
#Percentage for gender vs q3k
table(mastercopy2[,c("Gender","q3k")])[1,]/sum(table(mastercopy2[,c("Gender","q3k")])[1,])*100
table(mastercopy2[,c("Gender","q3k")])[2,]/sum(table(mastercopy2[,c("Gender","q3k")])[2,])*100
#Percentage for gender vs q4k
table(mastercopy2[,c("Gender","q4k")])[1,]/sum(table(mastercopy2[,c("Gender","q4k")])[1,])*100
table(mastercopy2[,c("Gender","q4k")])[2,]/sum(table(mastercopy2[,c("Gender","q4k")])[2,])*100
#Percentage for gender vs Q5
table(mastercopy2[,c("Gender","Q5K1")])[1,]/sum(table(mastercopy2[,c("Gender","Q5K1")])[1,])*100
table(mastercopy2[,c("Gender","Q5K1")])[2,]/sum(table(mastercopy2[,c("Gender","Q5K1")])[2,])*100
table(mastercopy2[,c("Gender","Q5K2")])[1,]/sum(table(mastercopy2[,c("Gender","Q5K2")])[1,])*100
table(mastercopy2[,c("Gender","Q5K2")])[2,]/sum(table(mastercopy2[,c("Gender","Q5K2")])[2,])*100
table(mastercopy2[,c("Gender","Q5K3")])[1,]/sum(table(mastercopy2[,c("Gender","Q5K3")])[1,])*100
table(mastercopy2[,c("Gender","Q5K3")])[2,]/sum(table(mastercopy2[,c("Gender","Q5K3")])[2,])*100
table(mastercopy2[,c("Gender","Q5K4")])[1,]/sum(table(mastercopy2[,c("Gender","Q5K4")])[1,])*100
table(mastercopy2[,c("Gender","Q5K4")])[2,]/sum(table(mastercopy2[,c("Gender","Q5K4")])[2,])*100
table(mastercopy2[,c("Gender","Q5K5")])[1,]/sum(table(mastercopy2[,c("Gender","Q5K5")])[1,])*100
table(mastercopy2[,c("Gender","Q5K5")])[2,]/sum(table(mastercopy2[,c("Gender","Q5K5")])[2,])*100
table(mastercopy2[,c("Gender","Q5K6")])[1,]/sum(table(mastercopy2[,c("Gender","Q5K6")])[1,])*100
table(mastercopy2[,c("Gender","Q5K6")])[2,]/sum(table(mastercopy2[,c("Gender","Q5K6")])[2,])*100
#Percentage for gender vs Q6K
table(mastercopy2[,c("Gender","Q6K")])[1,]/sum(table(mastercopy2[,c("Gender","Q6K")])[1,])*100
table(mastercopy2[,c("Gender","Q6K")])[2,]/sum(table(mastercopy2[,c("Gender","Q6K")])[2,])*100
#Percentage for gender vs Q7K
table(mastercopy2[,c("Gender","Q7K")])[1,]/sum(table(mastercopy2[,c("Gender","Q7K")])[1,])*100
table(mastercopy2[,c("Gender","Q7K")])[2,]/sum(table(mastercopy2[,c("Gender","Q7K")])[2,])*100
#Percentage for gender vs Q8K
table(mastercopy2[,c("Gender","Q8K")])[1,]/sum(table(mastercopy2[,c("Gender","Q8K")])[1,])*100
table(mastercopy2[,c("Gender","Q8K")])[2,]/sum(table(mastercopy2[,c("Gender","Q8K")])[2,])*100
#Percentage for gender vs Q9K
table(mastercopy2[,c("Gender","Q9K")])[1,]/sum(table(mastercopy2[,c("Gender","Q9K")])[1,])*100
table(mastercopy2[,c("Gender","Q9K")])[2,]/sum(table(mastercopy2[,c("Gender","Q9K")])[2,])*100
table(mastercopy2[,c("Gender","Q10C1")])[1,]/sum(table(mastercopy2[,c("Gender","Q7K")])[1,])*100
table(mastercopy2[,c("Gender","Q10C1")])[2,]/sum(table(mastercopy2[,c("Gender","Q7K")])[2,])*100
#Running DA
library(MASS)
Gender_Knowledge_DA <- lda(Gender~q2k+q3k+Q6K,data=mastercopy2)
Gender_Knowledge_DA
#LDA prediction
lda.testing <- predict(Gender_Knowledge_DA)
#confusion matrix
accuracy <- table(lda.testing$class,mastercopy2$Gender)
accuracy
sum(accuracy[row(accuracy) == col(accuracy)]) / sum(accuracy)
#Percentage for gender vs q1k
table(mastercopy2[,c("Gender","q1k")])[1,]/sum(table(mastercopy2[,c("Gender","q1k")])[1,])*100
table(mastercopy2[,c("Gender","q1k")])[2,]/sum(table(mastercopy2[,c("Gender","q1k")])[2,])*100
#Percentage for Education vs q1k
table(mastercopy2[,c("Education","q1k")])[1,]/sum(table(mastercopy2[,c("Education","q1k")])[1,])*100
table(mastercopy2[,c("Education","q1k")])[2,]/sum(table(mastercopy2[,c("Education","q1k")])[2,])*100
table(mastercopy2[,c("Education","q1k")])[3,]/sum(table(mastercopy2[,c("Education","q1k")])[3,])*100
table(mastercopy2[,c("Income","q1k")])
#Percentage for income vs q1k
table(mastercopy2[,c("Income","q1k")])[1,]/sum(table(mastercopy2[,c("Income","q1k")])[1,])*100
table(mastercopy2[,c("Income","q1k")])[2,]/sum(table(mastercopy2[,c("Income","q1k")])[2,])*100
table(mastercopy2[,c("Income","q1k")])[3,]/sum(table(mastercopy2[,c("Income","q1k")])[3,])*100
#Running PCA on Attitude and preceptions
names(mastercopy2[,c("Q10C1","Q10C2","Q10C3","Q10C4","Q10C5","Q10C6","Q10C7")])
res.pca2 <- prcomp(mastercopy2[,c("Q10C1","Q10C2","Q10C3","Q10C4","Q10C5","Q10C6","Q10C7")])
res.pca2
summary(res.pca2)
library("factoextra")
eig.val2 <- get_eigenvalue(res.pca2)
eig.val2
dimT2 <- c(1:8)
#Plot the cumulative percentage variance accounted for versus the index of the Components
plot(dimT2, eig.val2$cumulative.variance.percent, ylab = "Commulative Variance",xlab = "Principal Components")
#StreePlot
fviz_eig(res.pca2)
#Loading score
fviz_pca_var(res.pca2,axes = c(1,2),col.var = "contrib", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#Percentage for gender vs Q10C4
table(mastercopy2[,c("Gender","Q10C4")])[1,]/sum(table(mastercopy2[,c("Gender","Q10C4")])[1,])*100
table(mastercopy2[,c("Gender","Q10C4")])[2,]/sum(table(mastercopy2[,c("Gender","Q10C4")])[2,])*100
#Percentage for Education vs Q10C4
table(mastercopy2[,c("Education","Q10C4")])[1,]/sum(table(mastercopy2[,c("Education","Q10C4")])[1,])*100
table(mastercopy2[,c("Education","Q10C4")])[2,]/sum(table(mastercopy2[,c("Education","Q10C4")])[2,])*100
table(mastercopy2[,c("Education","Q10C4")])[3,]/sum(table(mastercopy2[,c("Education","Q10C4")])[3,])*100
table(mastercopy2[,c("Income","q1k")])
#Percentage for income vs q1k
table(mastercopy2[,c("Income","Q10C4")])[1,]/sum(table(mastercopy2[,c("Income","Q10C4")])[1,])*100
table(mastercopy2[,c("Income","Q10C4")])[2,]/sum(table(mastercopy2[,c("Income","Q10C4")])[2,])*100
table(mastercopy2[,c("Income","Q10C4")])[3,]/sum(table(mastercopy2[,c("Income","Q10C4")])[3,])*100
table(mastercopy2$Q10C1)
table(mastercopy2$Q10C2)
table(mastercopy2$Q10C3)
table(mastercopy2$Q10C4)
table(mastercopy2$Q10C5)
table(mastercopy2$Q10C6)
table(mastercopy2$Q10C7)
table(mastercopy2$Q10C7)
# Fit the full model
full.model <- lm(Gender ~., data = mastercopy2[,c("Gender","Q10C5","Q10C6","Q10C7")])
# Stepwise regression model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
summary(step.model)
#Data without question 19
data_without19 <- mastercopy2[,-(61:66)]
#Now we also dont need demographic as per requirement of project
data<-data_without19[,-(1:5)]
#DEcide number of initial factors
library(psych)
decidefactor <- fa.parallel(data, fm ='ml', fa = 'fa')
factana11 <- factanal(data,factors =11)
factana11
fact_ana11 <- fa(data,nfactors =11)
fa.diagram(fact_ana11)
summary(fact_ana11)
library(GPArotation)
factanatry1 <- fa(data,nfactors = 11)
library(psych)
fa.diagram(factana1)
colnames(factanatry1$loadings)
colnames(factanatry1$loadings)=c("PlasBeh",
"ReduInt",
"SysResp",
"SocAffect"
,"NatrConc",
"HealConc"
,"CondBeh"
,"IngEff"
,"BehChan"
,"ConEfft",
"Diff")
factana11 <- factanal(data,factors =11)
factana11
fact_ana11 <- fa(data,nfactors =11)
fa.diagram(fact_ana11)
library('caret')
#keeping only correlated variables keeping cutoff 0.2
data_corelated_try2 = findCorrelation(cor(data), cutoff=0.2)
data_corelated_try2
hc= sort(data_corelated_try2)
data_only_corelated_try2 = data[, c(hc)]
dim(data_only_corelated_try2)
#Decide number of factors
#DEcide number of initial factors
library(psych)
decidefactor <- fa.parallel(data_only_corelated_try2,fm ='ml', fa = 'fa')
factana11_0.2_1 <- factanal(data_only_corelated_try2, factors = 10)
factana11_0.2_1
fact_ana11_0.2_1 <- fa(data_only_corelated_try2,nfactors =10)
summary(fact_ana11_0.2_1)
#nomice copy
noMiceDataset<-Nomice
Edu.health1 <- table(noMiceDataset$Education,noMiceDataset$Q17P1)
Edu.health2 <- table(noMiceDataset$Education,noMiceDataset$Q17P2)
Edu.health3 <- table(noMiceDataset$Education,noMiceDataset$Q17P3)
Edu.health4 <- table(noMiceDataset$Education,noMiceDataset$Q17P4)
Edu.health5 <- table(noMiceDataset$Education,noMiceDataset$Q17P5)
table(noMiceDataset$Education)
ca.edu.health1 <- CA(Edu.health1, graph = TRUE)
ca.edu.health1
ca.edu.health2 <- CA(Edu.health2, graph = TRUE)
ca.edu.health2
ca.edu.health3 <- CA(Edu.health3, graph = TRUE)
ca.edu.health3
